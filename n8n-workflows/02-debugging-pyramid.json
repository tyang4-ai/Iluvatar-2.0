{
  "name": "Debugging Pyramid - 6 Layer Escalation",
  "active": false,
  "nodes": [
    {
      "parameters": {
        "path": "error-handler",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "error-webhook",
      "name": "Error Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "webhookId": "error-handler"
    },
    {
      "parameters": {
        "functionCode": "// Parse error and classify\nconst error = $input.item.json.body;\n\nfunction classifyError(error) {\n  const errorType = error.error_type || 'UNKNOWN';\n  const errorMessage = error.error_message || '';\n  \n  // Classification logic\n  if (errorMessage.includes('rate limit') || errorMessage.includes('429')) {\n    return { type: 'RATE_LIMIT', retries: 5, strategy: 'exponential_backoff' };\n  }\n  if (errorMessage.includes('timeout') || errorMessage.includes('ETIMEDOUT')) {\n    return { type: 'API_TIMEOUT', retries: 3, strategy: 'linear_backoff' };\n  }\n  if (errorType === 'SyntaxError' || errorMessage.includes('unexpected token')) {\n    return { type: 'SYNTAX_ERROR', retries: 1, strategy: 'lower_temperature' };\n  }\n  if (errorType === 'TestFailure' || errorMessage.includes('test failed')) {\n    return { type: 'TEST_FAILURE', retries: 0, strategy: 'escalate' };\n  }\n  if (errorMessage.includes('ECONNREFUSED') || errorMessage.includes('deployment')) {\n    return { type: 'DEPLOYMENT_ERROR', retries: 2, strategy: 'config_adjustment' };\n  }\n  \n  return { type: 'UNKNOWN', retries: 1, strategy: 'standard_retry' };\n}\n\nconst classification = classifyError(error);\n\nreturn {\n  json: {\n    error: error,\n    classification: classification,\n    attempt_number: error.attempt_number || 1,\n    max_retries: classification.retries,\n    layer: 'L1_SMART_RETRY'\n  }\n};"
      },
      "id": "classify-error",
      "name": "L1 - Classify Error",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [450, 300]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.attempt_number <= $json.max_retries }}",
              "value2": true
            }
          ]
        }
      },
      "id": "check-retry-limit",
      "name": "Check Retry Limit",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [650, 300]
    },
    {
      "parameters": {
        "functionCode": "// L1: Smart Retry with strategy\nconst error = $input.item.json.error;\nconst classification = $input.item.json.classification;\nconst attemptNumber = $input.item.json.attempt_number;\n\nlet waitTime = 0;\nlet modifiedInput = error.original_input;\n\nswitch (classification.strategy) {\n  case 'exponential_backoff':\n    waitTime = 1000 * Math.pow(2, attemptNumber - 1); // 1s, 2s, 4s, 8s, 16s\n    break;\n  \n  case 'linear_backoff':\n    waitTime = 5000 * attemptNumber; // 5s, 10s, 15s\n    break;\n  \n  case 'lower_temperature':\n    // Modify the request to lower temperature for more deterministic output\n    if (modifiedInput.temperature) {\n      modifiedInput.temperature = Math.max(0.3, modifiedInput.temperature - 0.2);\n    }\n    waitTime = 2000;\n    break;\n  \n  case 'config_adjustment':\n    // For deployment errors, might need to adjust config\n    waitTime = 10000;\n    break;\n  \n  default:\n    waitTime = 3000;\n}\n\n// Wait before retry\nawait new Promise(resolve => setTimeout(resolve, waitTime));\n\nreturn {\n  json: {\n    retry_action: 'EXECUTE',\n    modified_input: modifiedInput,\n    wait_time_ms: waitTime,\n    attempt_number: attemptNumber,\n    classification: classification\n  }\n};"
      },
      "id": "l1-smart-retry",
      "name": "L1 - Execute Smart Retry",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 200]
    },
    {
      "parameters": {
        "url": "={{ $json.error.retry_webhook_url }}",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.modified_input) }}"
      },
      "id": "retry-request",
      "name": "Retry Original Request",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1050, 200]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.success }}",
              "value2": true
            }
          ]
        }
      },
      "id": "check-retry-success",
      "name": "Check Retry Success",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1250, 200]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({layer: 'L1', status: 'RESOLVED', result: $json}) }}"
      },
      "id": "respond-l1-success",
      "name": "L1 Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1450, 100]
    },
    {
      "parameters": {
        "functionCode": "// Prepare Treebeard Primary (L2)\nconst fs = require('fs');\nconst systemPrompt = fs.readFileSync('/data/agents/11-treebeard.md', 'utf8');\n\nconst error = $('L1 - Classify Error').item.json.error;\n\nconst Redis = require('ioredis');\nconst redis = new Redis({host: process.env.REDIS_HOST || 'redis', port: 6379});\n\n// Get context from state\nconst stateData = await redis.hgetall('state:data');\nawait redis.quit();\n\nreturn {\n  json: {\n    agent: 'treebeard',\n    layer: 'L2_PRIMARY',\n    systemPrompt: systemPrompt,\n    input: {\n      error: error,\n      context: {\n        agent_name: error.agent_name,\n        file_path: error.file_path,\n        operation: error.operation,\n        state: stateData\n      },\n      previous_attempts: error.retry_history || [],\n      task: 'generate_3_solutions'\n    }\n  }\n};"
      },
      "id": "prepare-treebeard-l2",
      "name": "Prepare Treebeard L2",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({model: 'claude-opus-4-20250514', max_tokens: 8192, thinking: {type: 'enabled', budget_tokens: 10000}, messages: [{role: 'user', content: $json.systemPrompt + '\\n\\nInput:\\n' + JSON.stringify($json.input)}]}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "treebeard-l2-primary",
      "name": "Treebeard L2 - Generate Solutions",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1050, 400],
      "credentials": {
        "anthropicApi": {
          "id": "2",
          "name": "Anthropic API"
        }
      }
    },
    {
      "parameters": {
        "functionCode": "// Parse Treebeard L2 output\nconst response = $input.item.json.content.find(c => c.type === 'text')?.text;\nconst result = JSON.parse(response);\n\nreturn {\n  json: {\n    solutions: result.solutions,\n    recommended_solution: result.recommended_solution,\n    confidence_score: result.confidence_score\n  }\n};"
      },
      "id": "parse-treebeard-l2",
      "name": "Parse Treebeard L2 Solutions",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1250, 400]
    },
    {
      "parameters": {
        "batchSize": 1,
        "options": {}
      },
      "id": "split-solutions",
      "name": "Split Solutions for Sandbox",
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [1450, 400]
    },
    {
      "parameters": {
        "functionCode": "// Create sandbox environment and validate solution\nconst solution = $input.item.json;\nconst error = $('L1 - Classify Error').item.json.error;\n\n// Simulate sandbox validation (in real implementation, would spin up Docker container)\nfunction validateInSandbox(solution, error) {\n  // Syntax check\n  try {\n    if (solution.code) {\n      // In real implementation: run linter, type checker\n      const syntaxCheck = true; // Placeholder\n      if (!syntaxCheck) return { pass: false, reason: 'Syntax error' };\n    }\n  } catch (e) {\n    return { pass: false, reason: `Syntax validation failed: ${e.message}` };\n  }\n  \n  // Logic check\n  if (solution.changes_core_logic && solution.confidence < 0.7) {\n    return { pass: false, reason: 'Low confidence for core logic change' };\n  }\n  \n  // Dependency check\n  if (solution.new_dependencies && solution.new_dependencies.length > 0) {\n    // Check if dependencies are available\n    const unavailable = solution.new_dependencies.filter(dep => {\n      // In real implementation: check npm registry, PyPI, etc.\n      return false; // Placeholder\n    });\n    if (unavailable.length > 0) {\n      return { pass: false, reason: `Dependencies unavailable: ${unavailable.join(', ')}` };\n    }\n  }\n  \n  return { pass: true, reason: 'All checks passed' };\n}\n\nconst validation = validateInSandbox(solution, error);\n\nreturn {\n  json: {\n    solution: solution,\n    sandbox_validation: validation,\n    confidence_adjusted: validation.pass ? solution.confidence : solution.confidence * 0.5\n  }\n};"
      },
      "id": "sandbox-validate",
      "name": "L2 - Sandbox Validation",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1650, 400]
    },
    {
      "parameters": {
        "operation": "sort",
        "sortFieldsUi": {
          "sortField": [
            {
              "fieldName": "confidence_adjusted",
              "order": "descending"
            }
          ]
        }
      },
      "id": "rank-solutions",
      "name": "Rank Solutions by Confidence",
      "type": "n8n-nodes-base.itemLists",
      "typeVersion": 3,
      "position": [1850, 400]
    },
    {
      "parameters": {
        "functionCode": "// Select best solution and apply\nconst solutions = $input.all();\n\nconst bestSolution = solutions.find(s => s.json.sandbox_validation.pass);\n\nif (!bestSolution) {\n  return {\n    json: {\n      layer: 'L2',\n      status: 'FAILED',\n      reason: 'No solution passed sandbox validation',\n      escalate_to: 'L3'\n    }\n  };\n}\n\nreturn {\n  json: {\n    layer: 'L2',\n    status: 'RESOLVED',\n    solution: bestSolution.json.solution,\n    confidence: bestSolution.json.confidence_adjusted\n  }\n};"
      },
      "id": "select-best-solution",
      "name": "Select Best Solution",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [2050, 400]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.status }}",
              "value2": "RESOLVED"
            }
          ]
        }
      },
      "id": "check-l2-success",
      "name": "Check L2 Success",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [2250, 400]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}"
      },
      "id": "respond-l2-success",
      "name": "L2 Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2450, 300]
    },
    {
      "parameters": {
        "functionCode": "// Prepare Treebeard L3 - Alternative Strategies\nconst fs = require('fs');\nconst systemPrompt = fs.readFileSync('/data/agents/11-treebeard.md', 'utf8');\n\nconst error = $('L1 - Classify Error').item.json.error;\nconst failedSolutions = $('Select Best Solution').item.json.solutions || [];\n\nreturn {\n  json: {\n    agent: 'treebeard',\n    layer: 'L3_SECONDARY',\n    systemPrompt: systemPrompt,\n    input: {\n      error: error,\n      failed_solutions: failedSolutions,\n      task: 'alternative_strategies',\n      strategies: ['regenerate', 'simplify', 'alternative', 'workaround']\n    }\n  }\n};"
      },
      "id": "prepare-treebeard-l3",
      "name": "Prepare Treebeard L3",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [2250, 600]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({model: 'claude-opus-4-20250514', max_tokens: 8192, thinking: {type: 'enabled', budget_tokens: 10000}, messages: [{role: 'user', content: $json.systemPrompt + '\\n\\nInput:\\n' + JSON.stringify($json.input)}]}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "treebeard-l3-secondary",
      "name": "Treebeard L3 - Alternative Strategies",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [2450, 600],
      "credentials": {
        "anthropicApi": {
          "id": "2",
          "name": "Anthropic API"
        }
      }
    },
    {
      "parameters": {
        "functionCode": "// Parse L3 alternative strategies\nconst response = $input.item.json.content.find(c => c.type === 'text')?.text;\nconst result = JSON.parse(response);\n\nreturn {\n  json: {\n    layer: 'L3',\n    strategies_attempted: result.strategies_attempted,\n    successful_strategy: result.successful_strategy || null,\n    status: result.successful_strategy ? 'RESOLVED' : 'FAILED'\n  }\n};"
      },
      "id": "parse-treebeard-l3",
      "name": "Parse L3 Strategies",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [2650, 600]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.status }}",
              "value2": "RESOLVED"
            }
          ]
        }
      },
      "id": "check-l3-success",
      "name": "Check L3 Success",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [2850, 600]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}"
      },
      "id": "respond-l3-success",
      "name": "L3 Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [3050, 500]
    },
    {
      "parameters": {
        "functionCode": "// L4: Agent Swarm - Spawn 5 debugging agents\nconst error = $('L1 - Classify Error').item.json.error;\n\nconst swarmAgents = [\n  {\n    role: 'root_cause_analyzer',\n    prompt: 'Analyze the error and identify the root cause. Consider: code logic, dependencies, environment, timing, race conditions.'\n  },\n  {\n    role: 'similar_issue_searcher',\n    prompt: 'Search past failures in vector database for similar issues and their solutions.'\n  },\n  {\n    role: 'code_reviewer',\n    prompt: 'Review the problematic code for bugs: logic errors, edge cases, type mismatches, async issues.'\n  },\n  {\n    role: 'test_designer',\n    prompt: 'Design tests to isolate the issue. Propose minimal reproduction steps.'\n  },\n  {\n    role: 'architecture_advisor',\n    prompt: 'Suggest architectural fixes: refactoring, design patterns, separation of concerns.'\n  }\n];\n\nreturn swarmAgents.map(agent => ({\n  json: {\n    layer: 'L4',\n    agent_role: agent.role,\n    error: error,\n    prompt: agent.prompt\n  }\n}));"
      },
      "id": "spawn-swarm-l4",
      "name": "L4 - Spawn Agent Swarm",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [2850, 800]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({model: 'claude-sonnet-4-20250514', max_tokens: 4096, messages: [{role: 'user', content: $json.prompt + '\\n\\nError:\\n' + JSON.stringify($json.error)}]}) }}",
        "options": {
          "timeout": 120000
        }
      },
      "id": "execute-swarm-agent",
      "name": "Execute Swarm Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [3050, 800],
      "credentials": {
        "anthropicApi": {
          "id": "2",
          "name": "Anthropic API"
        }
      }
    },
    {
      "parameters": {
        "functionCode": "// Aggregate swarm insights and vote\nconst swarmResults = $input.all();\n\nconst insights = swarmResults.map(r => {\n  const response = r.json.content[0].text;\n  return {\n    role: $('L4 - Spawn Agent Swarm').item(r.index).json.agent_role,\n    analysis: response\n  };\n});\n\n// Simple voting: extract proposed solutions and count votes\nconst proposedSolutions = [];\nfor (const insight of insights) {\n  // In real implementation, use NLP to extract solutions\n  // Placeholder: assume each insight proposes a solution\n  proposedSolutions.push({\n    solution: insight.analysis.substring(0, 200),\n    votes: 1\n  });\n}\n\n// Require >70% consensus (4 out of 5 agents)\nconst totalVotes = swarmResults.length;\nconst consensusThreshold = Math.ceil(totalVotes * 0.7);\n\nconst consensus = proposedSolutions.find(s => s.votes >= consensusThreshold);\n\nreturn {\n  json: {\n    layer: 'L4',\n    swarm_insights: insights,\n    consensus_reached: !!consensus,\n    consensus_solution: consensus || null,\n    status: consensus ? 'RESOLVED' : 'FAILED'\n  }\n};"
      },
      "id": "aggregate-swarm-l4",
      "name": "L4 - Aggregate Swarm Insights",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [3250, 800]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.status }}",
              "value2": "RESOLVED"
            }
          ]
        }
      },
      "id": "check-l4-success",
      "name": "Check L4 Consensus",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [3450, 800]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}"
      },
      "id": "respond-l4-success",
      "name": "L4 Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [3650, 700]
    },
    {
      "parameters": {
        "functionCode": "// L5: Model Escalation - Opus with max thinking\nconst fs = require('fs');\nconst systemPrompt = fs.readFileSync('/data/agents/11-treebeard.md', 'utf8');\n\nconst error = $('L1 - Classify Error').item.json.error;\nconst swarmInsights = $('L4 - Aggregate Swarm Insights').item.json.swarm_insights;\n\nreturn {\n  json: {\n    agent: 'treebeard',\n    layer: 'L5_MODEL_ESCALATION',\n    systemPrompt: systemPrompt,\n    input: {\n      error: error,\n      previous_layers: {\n        l1: 'smart_retry_failed',\n        l2: 'validation_sandbox_failed',\n        l3: 'alternative_strategies_failed',\n        l4: 'agent_swarm_no_consensus'\n      },\n      swarm_insights: swarmInsights,\n      task: 'comprehensive_validation',\n      validation_checks: [\n        'syntax',\n        'type_safety',\n        'security',\n        'performance',\n        'integration',\n        'regression',\n        'edge_cases'\n      ]\n    }\n  }\n};"
      },
      "id": "prepare-treebeard-l5",
      "name": "Prepare L5 Model Escalation",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [3450, 1000]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({model: 'claude-opus-4-20250514', max_tokens: 16384, temperature: 0.0, thinking: {type: 'enabled', budget_tokens: 10000}, messages: [{role: 'user', content: $json.systemPrompt + '\\n\\nInput:\\n' + JSON.stringify($json.input)}]}) }}",
        "options": {
          "timeout": 600000
        }
      },
      "id": "treebeard-l5-escalation",
      "name": "Treebeard L5 - Max Intelligence",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [3650, 1000],
      "credentials": {
        "anthropicApi": {
          "id": "2",
          "name": "Anthropic API"
        }
      }
    },
    {
      "parameters": {
        "functionCode": "// Parse L5 comprehensive validation\nconst response = $input.item.json.content.find(c => c.type === 'text')?.text;\nconst result = JSON.parse(response);\n\nreturn {\n  json: {\n    layer: 'L5',\n    validation_results: result.validation_results,\n    all_checks_passed: result.validation_results.every(v => v.passed),\n    solution: result.solution,\n    status: result.validation_results.every(v => v.passed) ? 'RESOLVED' : 'FAILED'\n  }\n};"
      },
      "id": "parse-treebeard-l5",
      "name": "Parse L5 Validation",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [3850, 1000]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.status }}",
              "value2": "RESOLVED"
            }
          ]
        }
      },
      "id": "check-l5-success",
      "name": "Check L5 Success",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [4050, 1000]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}"
      },
      "id": "respond-l5-success",
      "name": "L5 Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [4250, 900]
    },
    {
      "parameters": {
        "functionCode": "// L6: Human Handoff - Generate comprehensive debug report\nconst error = $('L1 - Classify Error').item.json.error;\nconst l2Solutions = $('Select Best Solution').item.json.solutions || [];\nconst l3Strategies = $('Parse L3 Strategies').item.json.strategies_attempted || [];\nconst l4Insights = $('L4 - Aggregate Swarm Insights').item.json.swarm_insights || [];\nconst l5Validation = $('Parse L5 Validation').item.json.validation_results || [];\n\nconst totalAttempts = 3 + l2Solutions.length + l3Strategies.length + 5 + 1;\nconst timeElapsed = Math.floor((Date.now() - new Date(error.first_occurrence).getTime()) / 1000 / 60);\n\nconst debugReport = {\n  alert_type: 'HUMAN_INTERVENTION_REQUIRED',\n  emoji: 'ðŸš¨',\n  error_summary: {\n    component: error.file_path || error.component,\n    error_type: error.error_type,\n    error_message: error.error_message,\n    first_occurrence: error.first_occurrence\n  },\n  escalation_timeline: {\n    total_attempts: totalAttempts,\n    time_elapsed_minutes: timeElapsed,\n    layers: [\n      { layer: 'L1', name: 'Smart Retry', attempts: 3, result: 'FAILED' },\n      { layer: 'L2', name: 'Treebeard Primary', attempts: l2Solutions.length, result: 'FAILED' },\n      { layer: 'L3', name: 'Treebeard Secondary', attempts: l3Strategies.length, result: 'FAILED' },\n      { layer: 'L4', name: 'Agent Swarm', attempts: 5, result: 'NO_CONSENSUS' },\n      { layer: 'L5', name: 'Model Escalation', attempts: 1, result: 'VALIDATION_FAILED' }\n    ]\n  },\n  ai_generated_hypotheses: [\n    'Hypothesis 1: Configuration mismatch between environments',\n    'Hypothesis 2: Race condition or timing issue',\n    'Hypothesis 3: Dependency version conflict',\n    'Hypothesis 4: Missing environment variable or secret',\n    'Hypothesis 5: Network or firewall blocking connection'\n  ],\n  reproduction_steps: [\n    '1. Set up environment: [list dependencies]',\n    '2. Navigate to: ' + (error.file_path || 'component location'),\n    '3. Execute: [command or action]',\n    '4. Observe error: ' + error.error_message\n  ],\n  suggested_actions: [\n    '1. Check configuration files and environment variables',\n    '2. Add detailed logging around line ' + (error.line_number || 'N/A'),\n    '3. Test in isolation (remove dependencies one by one)',\n    '4. Review recent changes that might have introduced the issue'\n  ],\n  attachments: {\n    debug_report_json: '/tmp/debug-report.json',\n    error_log: '/tmp/error.log',\n    full_context: '/tmp/full-context.json'\n  },\n  pipeline_status: 'PAUSED',\n  resume_instructions: 'React with âœ… when fixed, and I will resume the pipeline.'\n};\n\nreturn {\n  json: {\n    layer: 'L6',\n    status: 'HUMAN_HANDOFF',\n    debug_report: debugReport\n  }\n};"
      },
      "id": "generate-debug-report-l6",
      "name": "L6 - Generate Debug Report",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [4050, 1200]
    },
    {
      "parameters": {
        "operation": "executeCommand",
        "command": "PUBLISH",
        "key": "agent:Pippin",
        "options": {
          "args": "={{ JSON.stringify({from: 'Treebeard', to: 'Pippin', type: 'human_handoff', payload: $json.debug_report}) }}"
        }
      },
      "id": "publish-to-pippin-l6",
      "name": "L6 - Notify Pippin",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [4250, 1200],
      "credentials": {
        "redis": {
          "id": "1",
          "name": "Redis - ILUVATAR"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeCommand",
        "command": "HMSET",
        "key": "state:data",
        "options": {
          "args": "={{ JSON.stringify(['pipeline_status', 'PAUSED', 'human_intervention_required', 'true', 'debug_report', JSON.stringify($('L6 - Generate Debug Report').item.json.debug_report)]) }}"
        }
      },
      "id": "pause-pipeline-l6",
      "name": "L6 - Pause Pipeline",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [4450, 1200],
      "credentials": {
        "redis": {
          "id": "1",
          "name": "Redis - ILUVATAR"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($('L6 - Generate Debug Report').item.json) }}"
      },
      "id": "respond-l6-handoff",
      "name": "L6 Handoff Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [4650, 1200]
    }
  ],
  "connections": {
    "Error Webhook Trigger": {
      "main": [
        [
          {
            "node": "L1 - Classify Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L1 - Classify Error": {
      "main": [
        [
          {
            "node": "Check Retry Limit",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Retry Limit": {
      "main": [
        [
          {
            "node": "L1 - Execute Smart Retry",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Treebeard L2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L1 - Execute Smart Retry": {
      "main": [
        [
          {
            "node": "Retry Original Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retry Original Request": {
      "main": [
        [
          {
            "node": "Check Retry Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Retry Success": {
      "main": [
        [
          {
            "node": "L1 Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Treebeard L2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Treebeard L2": {
      "main": [
        [
          {
            "node": "Treebeard L2 - Generate Solutions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Treebeard L2 - Generate Solutions": {
      "main": [
        [
          {
            "node": "Parse Treebeard L2 Solutions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Treebeard L2 Solutions": {
      "main": [
        [
          {
            "node": "Split Solutions for Sandbox",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Solutions for Sandbox": {
      "main": [
        [
          {
            "node": "L2 - Sandbox Validation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L2 - Sandbox Validation": {
      "main": [
        [
          {
            "node": "Rank Solutions by Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rank Solutions by Confidence": {
      "main": [
        [
          {
            "node": "Select Best Solution",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Select Best Solution": {
      "main": [
        [
          {
            "node": "Check L2 Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check L2 Success": {
      "main": [
        [
          {
            "node": "L2 Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Treebeard L3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Treebeard L3": {
      "main": [
        [
          {
            "node": "Treebeard L3 - Alternative Strategies",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Treebeard L3 - Alternative Strategies": {
      "main": [
        [
          {
            "node": "Parse L3 Strategies",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse L3 Strategies": {
      "main": [
        [
          {
            "node": "Check L3 Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check L3 Success": {
      "main": [
        [
          {
            "node": "L3 Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "L4 - Spawn Agent Swarm",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L4 - Spawn Agent Swarm": {
      "main": [
        [
          {
            "node": "Execute Swarm Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Swarm Agent": {
      "main": [
        [
          {
            "node": "L4 - Aggregate Swarm Insights",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L4 - Aggregate Swarm Insights": {
      "main": [
        [
          {
            "node": "Check L4 Consensus",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check L4 Consensus": {
      "main": [
        [
          {
            "node": "L4 Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare L5 Model Escalation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare L5 Model Escalation": {
      "main": [
        [
          {
            "node": "Treebeard L5 - Max Intelligence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Treebeard L5 - Max Intelligence": {
      "main": [
        [
          {
            "node": "Parse L5 Validation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse L5 Validation": {
      "main": [
        [
          {
            "node": "Check L5 Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check L5 Success": {
      "main": [
        [
          {
            "node": "L5 Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "L6 - Generate Debug Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L6 - Generate Debug Report": {
      "main": [
        [
          {
            "node": "L6 - Notify Pippin",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L6 - Notify Pippin": {
      "main": [
        [
          {
            "node": "L6 - Pause Pipeline",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "L6 - Pause Pipeline": {
      "main": [
        [
          {
            "node": "L6 Handoff Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2025-12-14T00:00:00.000Z",
  "versionId": "1"
}
