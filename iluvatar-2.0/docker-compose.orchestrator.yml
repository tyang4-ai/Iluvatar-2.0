# =============================================================================
# ILUVATAR 3.0 - Orchestrator Service
# =============================================================================
# Always-running service that manages multiple hackathon containers.
# Includes Discord bot, API server, and shared infrastructure.
#
# Usage:
#   docker-compose -f docker-compose.orchestrator.yml up -d
#
# Environment variables required:
#   - ANTHROPIC_API_KEY
#   - OPENAI_API_KEY (optional)
#   - DISCORD_BOT_TOKEN
#   - DATABASE_URL
#   - AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY (for S3)
#   - GITHUB_TOKEN (for repo management)
# =============================================================================

version: '3.8'

services:
  # =========================================================================
  # Core Orchestrator Service
  # =========================================================================
  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    container_name: iluvatar_orchestrator
    ports:
      - "3001:3001"  # API server
    environment:
      # Node
      - NODE_ENV=production
      - PORT=3001

      # Database
      - DATABASE_URL=postgresql://iluvatar:${POSTGRES_PASSWORD}@postgres:5432/iluvatar
      - REDIS_URL=redis://redis:6379

      # AI Providers
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LOCAL_MODEL_URL=${LOCAL_MODEL_URL:-}

      # Discord
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - DISCORD_CLIENT_ID=${DISCORD_CLIENT_ID}
      - DISCORD_GUILD_ID=${DISCORD_GUILD_ID}

      # AWS (for S3 archival)
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - S3_ARCHIVE_BUCKET=${S3_ARCHIVE_BUCKET:-iluvatar-archives}

      # GitHub
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_ORG=${GITHUB_ORG:-}

      # Vercel (for deployments)
      - VERCEL_TOKEN=${VERCEL_TOKEN:-}
      - VERCEL_TEAM_ID=${VERCEL_TEAM_ID:-}

      # Railway (for deployments)
      - RAILWAY_TOKEN=${RAILWAY_TOKEN:-}

      # Docker socket for container management
      - DOCKER_HOST=unix:///var/run/docker.sock

      # Warm pool settings
      - WARM_POOL_SIZE=${WARM_POOL_SIZE:-2}
      - MAX_CONCURRENT_HACKATHONS=${MAX_CONCURRENT_HACKATHONS:-10}

      # Budget defaults
      - DEFAULT_BUDGET=${DEFAULT_BUDGET:-50.00}
      - GLOBAL_BUDGET_LIMIT=${GLOBAL_BUDGET_LIMIT:-500.00}
    volumes:
      # Docker socket for spawning hackathon containers
      - /var/run/docker.sock:/var/run/docker.sock

      # Orchestrator code
      - ./orchestrator:/app/orchestrator
      - ./core:/app/core
      - ./agents:/app/agents

      # Shared data
      - orchestrator_data:/app/data
      - hackathon_workspaces:/workspaces
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - iluvatar_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =========================================================================
  # Redis - Shared state and message bus
  # =========================================================================
  redis:
    image: redis:7-alpine
    container_name: iluvatar_redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - iluvatar_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =========================================================================
  # PostgreSQL - Hackathon registry and persistent storage
  # =========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: iluvatar_postgres
    environment:
      - POSTGRES_DB=iluvatar
      - POSTGRES_USER=iluvatar
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Initialize with both 2.0 and 3.0 schemas
      - ./setup/init-db.sql:/docker-entrypoint-initdb.d/01-init-db.sql
      - ./setup/hackathon-registry.sql:/docker-entrypoint-initdb.d/02-hackathon-registry.sql
    restart: unless-stopped
    networks:
      - iluvatar_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U iluvatar -d iluvatar"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =========================================================================
  # Qdrant - Vector database for semantic search
  # =========================================================================
  vectordb:
    image: qdrant/qdrant:latest
    container_name: iluvatar_vectordb
    ports:
      - "6333:6333"
      - "6334:6334"  # gRPC
    volumes:
      - vectordb_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - iluvatar_network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6333/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =========================================================================
  # Grafana - Monitoring dashboard
  # =========================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: iluvatar_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SECURITY_ADMIN_USER=admin
      - GF_INSTALL_PLUGINS=redis-datasource,grafana-postgresql-datasource
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3000}
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - redis
      - postgres
    restart: unless-stopped
    networks:
      - iluvatar_network

  # =========================================================================
  # Prometheus - Metrics collection
  # =========================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: iluvatar_prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./setup/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - iluvatar_network

  # =========================================================================
  # Nginx - Reverse proxy and load balancer
  # =========================================================================
  nginx:
    image: nginx:alpine
    container_name: iluvatar_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./setup/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./setup/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - orchestrator
      - grafana
    restart: unless-stopped
    networks:
      - iluvatar_network

# =============================================================================
# Volumes
# =============================================================================
volumes:
  # Core data
  redis_data:
    driver: local
  postgres_data:
    driver: local
  vectordb_data:
    driver: local

  # Orchestrator data
  orchestrator_data:
    driver: local
  hackathon_workspaces:
    driver: local

  # Monitoring
  grafana_data:
    driver: local
  prometheus_data:
    driver: local
  nginx_logs:
    driver: local

# =============================================================================
# Network
# =============================================================================
networks:
  iluvatar_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
